---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

# Theory

## Part 1

Import and inspect the data
```{r}
library(rethinking)
data(Howell1)
df <-  Howell1
head(df)
```

Select only adults and plot 
```{r}
df2 <- df[df$age >= 18,]
dens(df2$height)
```
Have a look at the priors for the height and variance
```{r}
curve( dnorm( x, 178, 20), from=100, to=250)
curve( dunif( x, 0, 50), from=-10, to=60)
```

Sample the priors for the height
```{r}
sample_mu <- rnorm( 1e4, 178, 20)
sample_sigma <- runif( 1e4, 0, 50) 
prior_h <- rnorm( 1e4, sample_mu, sample_sigma) 
dens( prior_h)
```

Estimate the posterior. Note that the range of mu.list and sigma.list is based on knowing the outcome from the posterior. Then the posterior probability for each point in the grid is caluclated.
```{r}
mu.list <- seq( from=140, to=160, length.out=200) 
sigma.list <- seq( from=4, to=9, length.out=200) 
post <- expand.grid( mu=mu.list, sigma=sigma.list) 

post$LL <- sapply( 1:nrow(post), function(i) sum( dnorm(
  df2$height,
  mean=post$mu[i], 
  sd=post$sigma[i], log=TRUE))) 
post$prod <- post$LL +
  dnorm( post$mu, 178, 20, TRUE) + 
  dunif( post$sigma, 0, 50, TRUE) 
post$prob <- exp( post$prod - max(post$prod))
```


A quick plot shows the probability of different heights and variances.
```{r}
contour_xyz( post$mu, post$sigma, post$prob)
image_xyz( post$mu, post$sigma, post$prob)
```
Adults are expected to be around 155 cm tall.  



Sampeling from the posterior is an alternative way of identifying the same pattern. This is the more flexible approach. 
```{r}
sample.rows <- sample( 1:nrow(post), size=1e4, replace=TRUE, prob=post$prob) 
sample.mu <- post$mu[ sample.rows] 
sample.sigma <- post$sigma[ sample.rows]
```

Plotting the samples with alpha less than 1.
```{r}
par(pty="s")
plot( sample.mu, sample.sigma, cex=0.5, pch=16, col=col.alpha(rangi2,0.02))
```
This shows that simulations from the posterior gives the same visual impression as the calulated posterior.

Some other ways the posterior samples can be described:
```{r}
dens( sample.mu, adj=1) 
dens( sample.sigma)
HPDI( sample.mu) 
HPDI( sample.sigma)
```

## Part 2

```{r}
rm(list=ls())
```


Loading the data and selecting only adults.
```{r}
library(rethinking)
data(Howell1) 
df <- Howell1 
df2 <- df[ df$age >= 18,]
```

Define the model and find the maximum a posteriori estimates
```{r}
flist <- alist( 
  height ~ dnorm( mu, sigma),
  mu ~ dnorm( 178, 20),
  sigma ~ dunif( 0, 50) 
  )
m4.1 <- map( flist, data=df2)
```

Summ ary of the fitted moddel
```{r}
precis(m4.1)
vcov(m4.1)
cov2cor(vcov(m4.1))
```

# Part 3, adding a predictor

```{r}
rm(list=ls())
```


Load and select the data
```{r}
library(rethinking) 
data(Howell1)
df <- Howell1 
df2 <- df[ df$age >= 18,] 
```

A quick visual inspection
```{r}
plot(df2$height ~ df2$weight)
```

Define and fit the model. Then inspect it
```{r}
m4.3 <- map( alist( height ~ dnorm( mu, sigma),
                    mu <- a + b*weight, 
                    a ~ dnorm( 156, 100), 
                    b ~ dnorm( 0, 10), 
                    sigma ~ dunif( 0, 50) ) ,
             data=df2)
m4.3
```

A plot with the line from the MAP estimated  parameters s
```{r}
plot( height ~ weight, data=df2) 
abline( a=coef(m4.3)["a"], b=coef(m4.3)["b"])
```

The estimated paramters have a distribution (joint probability distribution).
Selecting 10 samples and estimating the parameters to show the inner workings of the model.
```{r}
N <- 10 
dfN <- df2[ 1:N,] 
mN <- map( alist( height ~ dnorm( mu, sigma), 
                  mu <- a + b*weight,
                  a ~ dnorm( 178, 100),
                  b ~ dnorm( 0, 10),
                  sigma ~ dunif( 0, 50) ), data=dfN)

```

```{r}
#extract 20 samples from the posterior
post <- extract.samples( mN, n=20) 
#display raw data and sample size
plot( dfN$weight,
      dfN$height,
      xlim=range(df2$weight),
      ylim=range(df2$height), 
      col=rangi2, 
      xlab="weight", 
      ylab="height") 
mtext(concat("N = ",N)) 
#plot the lines, with transparency 
for (i in 1:20) 
  abline( a=post$a[i], b=post$b[i], col=col.alpha("black",0.3))
```

Link is a function that can be used to get the simulated expected model value conditional on the weight. This can be used to make a similar visualization to the one using 10 data points and 20 simulations but with all the data. 
```{r}
weight.seq=seq(25,70, by = 1) 
mu <- link( m4.3, data=data.frame(weight=weight.seq))
```

Plotting the different mu values
```{r}
#use type="n" to hide raw data, blank plot with axis
plot( height ~ weight, df2, type="n") 

#loop over the first 100 sample rows and plot the mu value coresponding to each weight
for (i in 1:100) 
  points( weight.seq, mu[i,], pch=16, col=col.alpha(rangi2,0.1))
```

The simulateded mu values can be summarised and then plotted
```{r}
#summarize the distribution of mu
mu.mean <- apply( mu, 2, mean) 
mu.HPDI <- apply( mu, 2, HPDI, prob=0.89)
#plot raw data 
#fading out points to make line and interval more visible 
plot( height ~ weight, data=df2, col=col.alpha(rangi2,0.5))
#plot the MAP line, aka the mean mu for each weight
lines( weight.seq, mu.mean) 
#plot a shaded region for 89% HPDI 
shade( mu.HPDI, weight.seq)

```

# Easy

```{r}
rm(list=ls())
```

## Question 1
The first line

## Question 2
Two parameters

## Question 3

$$ 
\textrm{P}( \mu,\sigma \mid y)   = \frac{ \textrm{P}( y \mid \mu,\sigma ) \times \textrm{P}(\mu,\sigma)} {\textrm{P}(y)} 
$$
The priors of $\mu$ and $\sigma$ are independent. The joint prior is a product of their individual priors.  Let f be the normal distribution. 
$$ 
\textrm{P}( \mu,\sigma \mid y)   = \frac{ \prod f(y \mid \mu,\sigma ) \times f(\mu \mid 0, 10) \times 1/10} {\int_{\mu} \int_{\sigma} \prod f(y \mid \mu,\sigma ) } 
$$

## Question 4

line 2


## Question 5

Three, the output of the linear model is not a parameter. 

# Medium

```{r}
rm(list=ls())
```

## Question 1

```{r}
n <-  100
mu <-  rnorm(n, 0, 10)
sigma <-  runif(n, 0, 10)
heights <-  rnorm(n, mu, sigma)
```


## Question 2

```{r}
flist <- alist(
  y ~ dnorm(mu, sigma),
  mu ~ dnorm(0,10),
  sigma ~ dunif(0,10)
)
```

## Question 3

$$
\begin{aligned}
& y_i \sim \mathrm{Normal}(\mu_i, \sigma)  \\
& \mu_i = \alpha + \beta x_i \\
& \alpha \sim \mathrm{Normal}(0, 50)  \\
& \beta \sim \mathrm{Uniform}(0, 10) \\
& \sigma \sim \mathrm{Uniform}(0, 50)
\end{aligned}
$$


## Question 4

$$
\begin{aligned}
& h_i \sim \mathrm{Normal}(\mu_i, \sigma)  \\
& \mu_i = \alpha + \beta y_i \\
& \alpha \sim \mathrm{Normal}(170, 20)  \\
& \beta \sim \mathrm{Normal}(0, 2) \\
& \sigma \sim \mathrm{Uniform}(0,20)
\end{aligned}
$$


## Question 3

Yes, it looks like the students are children. If I had known this I would have chosen a diffrent model. Picking such a strong prior was based on adults and that growth even for young students i likely to be zero or close to zero. 

## Question 4

This depends on your source of information. If you have checked the same data that will be used in the moddeling I might not want to change anything. If this is based on seperate data then it should be taken into account. Assume only 5 students. Having checked that the vairance is small does not mean you should update the prior with this information. That means using the data twice...

# Hard

```{r}
rm(list=ls())
```


## Question 1

*The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals. That is, fill in the table below, using model-based predictions.*

Load and select the data
```{r}
library(rethinking) 
data(Howell1)
df <- Howell1 
```

A quick look at the relationship
```{r}
plot(df$weight, df$height)
```

The people from the census with missings heights are all above 30 kg. Subsetting the data will make modeling easier beacuse some of the nonlinearity will be taken out. This is good becaues it seems unlikely to be any information about adult height which can be extracted based on data from children. This is true for people with exeptionally low weight also.

```{r}
df2 <-  df[df$weight > 30,]
```

```{r}
plot(df2$weight,df2$height)
```
This looks like the same data as the data from only adults. A quick check: 

```{r}
sum(df2$age > 18)/nrow(df2)
```
It is close to only the adults in the subset, but it is not guarantee that the census is of adults only.

```{r}
plot(df2$weight,df2$height, col=c("red","blue")[as.numeric(df2$age>18)+1])
```
Since children above 30 kg seems to follow the same patern as adults there is no reason to take the data out. The subset is kept.


Setting up the model. Instead of thinking to much about the priors I'm just putting in som really weak priors and let the data talk. 
```{r}
flist <- alist(
  height ~ dnorm(mu,sigma),
  mu <- a + b*weight,
  a ~ dnorm(170,50),
  b ~ dnorm(0, 20),
  sigma ~ dunif(0, 50)
)
```


```{r}
model_q1 <- map(flist, data = df2)
``` 


Individual weight expected height 89% interval 1 
```{r}
table_weights <- c(46.95, 43.72, 64.78, 32.59, 54.63)

height_simulations <- sim(model_q1, data=data.frame(weight=table_weights))
```


```{r}
height_HPDI <- apply( height_simulations, 2, HPDI, prob=0.89)
height_mean <-  apply(height_simulations, 2, mean)
```


```{r}
data.frame(Individual = seq(1,5), 
           weight = table_weights,
           mean = height_mean,
           hpdi_low = height_HPDI[1,],
           hpdi_high = height_HPDI[2,] )
```


## Question 2
*Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right, you should end up with a new data frame with 192 rows in it.*

*(a) Fit a linear regression to these data, using map. Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets?*

*(b) Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Superimpose the MAP regression line and 89% HPDI for the mean. Also superimpose the 89% HPDI for predicted heights.*

*(c) What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don’t have to write any new code. Just explain what the model appears to be doing a bad job of, and what you hypothesize would be a better model.*

```{r}
df3 <- df[df$age<18,]
str(df3)
```

```{r}
flist <- alist(
  height ~ dnorm(mu,sigma),
  mu <- a + b*weight,
  a ~ dnorm(170,100),
  b ~ dnorm(0, 20),
  sigma ~ dunif(0,50)
)
```

```{r}
model_children <- map(flist, data = df3)
```

```{r}
precis(model_children, cor = TRUE)
```

**(a) 10 units increase in weights results in about 2.7cm/kg*10 kg = 27 cm **


```{r}
weight_seq <-  seq(2,70,by=0.5)
mu <-  link(model_children, data = data.frame(weight = weight_seq))
height <- sim(model_children, data = data.frame(weight = weight_seq))
```


**(b) **

```{r}
mu.mean <- apply( mu, 2, mean) 
mu.HPDI <- apply( mu, 2, HPDI, prob=0.89)
height.HDPI <-  apply(height, 2, HPDI, prob=0.89)

#plot raw data 
#fading out points to make line and interval more visible 
plot( height ~ weight, data=df3, col=col.alpha(rangi2,0.5), xaxt = "n")
#plot the MAP line, aka the mean mu for each weight
lines(weight_seq, mu.mean) 
#plot a shaded region for 89% HPDI 
shade(mu.HPDI,weight_seq)
shade(height.HDPI , weight_seq)
```
**(c) It is not a good model and the uncertainty is irrelevant compared to the poor fit. Taking into account the non-linearity would result in a model which fits the data. This will result in less variance and a more accurat predictions.**


## Question 3

*Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body weight that scales with height!” Let’s take your colleague’s advice and see what happens.*

Talking the log does not allow for centering. This means a prior for alpha is harder to get right. I'm going for a standard weak gausian.
```{r}
flist <- alist(
  height ~ dnorm(mu,sigma),
  mu <- alpha + beta*log(weight),
  alpha ~ dnorm(178,100),
  beta ~ dnorm(0,100),
  sigma ~ dunif(0,50)
  )
```

```{r}
log_model <- map(flist, data = df)
```

```{r}
precis(log_model, corr = TRUE)
```


```{r}
weight_seq <-  seq(0,65,by=0.5)
mu <-  link(log_model, data = data.frame(weight = weight_seq))
height <- sim(log_model, data = data.frame(weight = weight_seq))
```

```{r}
mu.mean <- apply( mu, 2, mean) 
mu.HPDI <- apply( mu, 2, HPDI, prob=0.97)
height.HDPI <-  apply(height, 2, HPDI, prob=0.97)
```



```{r}
plot(height ~ weight, data = df, col = col.alpha(rangi2, 0.4))
#plot the MAP line, aka the mean mu for each weight
lines(weight_seq, mu.mean) 
#plot a shaded region for 89% HPDI 
shade(mu.HPDI,weight_seq, col = col.alpha("black", 0.35))
shade(height.HDPI, weight_seq, col = col.alpha("blue", 0.1))

```

